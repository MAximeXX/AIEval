# -*- coding: utf-8 -*-
from __future__ import annotations

import asyncio
import json
import os
import random
from collections import Counter, defaultdict
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

from openai import OpenAI
from sqlalchemy import select
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.models.survey import (
    LlmEval,
    ParentNote,
    SurveyResponse,
    TeacherReview,
    CompositeResponse,
)
from app.models.user import GradeBand, User


@dataclass
class LlmConfig:
    api_base: Optional[str] = None
    api_key: Optional[str] = None
    model: str = "qwen-max"

    def normalized_base_url(self) -> Optional[str]:
        if not self.api_base:
            return None
        base = self.api_base.rstrip("/")
        if not base.endswith("/v1"):
            base = f"{base}/v1"
        return base


FREQUENCY_SCORES = {"æ¯å¤©": 3, "ç»å¸¸": 2, "å¶å°”": 1}
SKILL_SCORES = {"ç†Ÿç»ƒ": 3, "ä¸€èˆ¬": 2, "ä¸ä¼š": 1}


def _normalize_minor_category(
    major: str | None,
    minor: str | None,
    grade_band: GradeBand | None,
) -> str:
    major = (major or "").strip()
    minor = (minor or "").strip()
    if not minor:
        return major or "ç»¼åˆåŠ³åŠ¨"
    if grade_band in (GradeBand.MID, GradeBand.HIGH):
        if minor in {"å®¶ç”¨å™¨å…·ä½¿ç”¨ä¸Žç»´æŠ¤", "ç”µå™¨ä½¿ç”¨ä¸Žç»´æŠ¤"}:
            return "ç”µå™¨ä½¿ç”¨ä¸Žç»´æŠ¤"
        if minor in {"å†œä¸šç”Ÿäº§åŠ³åŠ¨", "ç§æ¤åŠ³åŠ¨"}:
            return "å†œä¸šåŠ³åŠ¨"
    return minor


def _compute_category_statistics(
    survey: SurveyResponse,
) -> tuple[dict[str, float], dict[str, list[str]]]:
    grade_band = survey.grade_band
    scores_by_category: dict[str, list[float]] = defaultdict(list)
    traits_by_category: dict[str, list[str]] = defaultdict(list)
    for response_item in survey.items:
        survey_item = response_item.item
        if not survey_item:
            continue
        category = _normalize_minor_category(
            survey_item.major_category, survey_item.minor_category, grade_band
        )
        freq_score = FREQUENCY_SCORES.get((response_item.frequency or "").strip(), 0)
        skill_score = SKILL_SCORES.get((response_item.skill or "").strip(), 0)
        score = (freq_score * 0.5) + (skill_score * 0.5)
        scores_by_category[category].append(score)
        if response_item.traits:
            traits_by_category[category].extend(
                [trait.strip() for trait in response_item.traits if trait.strip()]
            )
    averages = {
        category: round(sum(scores) / len(scores), 2) if scores else 0.0
        for category, scores in scores_by_category.items()
    }
    return averages, traits_by_category


def _select_top_labels(
    score_map: dict[str, float], top_n: int, rng: random.Random
) -> list[str]:
    if not score_map:
        return []
    grouped: dict[float, list[str]] = defaultdict(list)
    for label, score in score_map.items():
        grouped[score].append(label)
    selected: list[str] = []
    for score in sorted(grouped.keys(), reverse=True):
        candidates = sorted(set(grouped[score]))
        need = top_n - len(selected)
        if need <= 0:
            break
        if len(candidates) <= need:
            selected.extend(candidates)
        else:
            selected.extend(rng.sample(candidates, need))
    return selected[:top_n]


def _extract_stage_order(label: str) -> int:
    digits = "".join(ch for ch in str(label) if ch.isdigit())
    return int(digits) if digits else 0


def _extract_composite_summary(composite: Optional[CompositeResponse]) -> dict[str, Any]:
    if not composite or not isinstance(composite.payload, dict):
        return {"stage": None, "scores": {}}
    q3 = composite.payload.get("q3")
    if not isinstance(q3, dict) or not q3:
        return {"stage": None, "scores": {}}
    stage = max(q3.keys(), key=_extract_stage_order)
    stage_scores = q3.get(stage) or {}
    cleaned = {
        key: value
        for key, value in stage_scores.items()
        if value is not None
    }
    return {"stage": stage, "scores": cleaned}


class LlmService:
    """å°è£… LLM è¯„ä¼°é€»è¾‘ï¼Œå¯å¯¹æŽ¥å¤–éƒ¨ Qwen æœåŠ¡ï¼›è‹¥æœªé…ç½®åˆ™ä½¿ç”¨æœ¬åœ°å¯å‘å¼ç”Ÿæˆã€‚"""

    def __init__(self, config: Optional[LlmConfig] = None) -> None:
        cfg = config or LlmConfig(
            api_base=settings.qwen_api_base or os.getenv("QWEN_API_BASE"),
            api_key=settings.qwen_api_key or os.getenv("QWEN_API_KEY"),
            model=settings.qwen_model or os.getenv("QWEN_MODEL"),
        )
        self.config = cfg
        self._client: OpenAI | None = None
        if cfg.api_key:
            base_url = cfg.normalized_base_url()
            if base_url:
                self._client = OpenAI(base_url=base_url, api_key=cfg.api_key)
            else:
                self._client = OpenAI(api_key=cfg.api_key)

    async def generate_once(
        self,
        db: AsyncSession,
        student: User,
        survey: SurveyResponse,
        parent_note: ParentNote,
        teacher_review: TeacherReview,
        payload: Dict[str, Any],
        *,
        force_refresh: bool = False,
    ) -> LlmEval:
        from sqlalchemy import select, update

        result = await db.execute(
            select(LlmEval).where(LlmEval.student_id == student.id)
        )
        existing: LlmEval | None = result.scalar_one_or_none()
        if existing and not force_refresh:
            return existing

        raw_response = await self._invoke(payload)
        final_message, careers = self._build_output_message(payload, raw_response)
        stored_payload = dict(payload)
        stored_payload["recommended_careers"] = careers
        stored_payload["llm_raw_response"] = raw_response

        stmt = insert(LlmEval).values(
            student_id=student.id,
            content=final_message,
            payload=stored_payload,
            generated_at=datetime.now(timezone.utc),
        )
        await db.execute(
            stmt.on_conflict_do_update(
                index_elements=[LlmEval.student_id],
                set_={
                    "content": final_message,
                    "payload": stored_payload,
                    "generated_at": datetime.now(timezone.utc),
                },
            )
        )
        await db.flush()
        refreshed_result = await db.execute(
            select(LlmEval).where(LlmEval.student_id == student.id)
        )
        return refreshed_result.scalar_one()

    async def _invoke(self, payload: Dict[str, Any]) -> str:
        if not self._client:
            raise RuntimeError("LLM client æœªé…ç½®ï¼Œæ— æ³•è°ƒç”¨è¿œç¨‹æŽ¥å£")
        return await self._call_remote(payload)

    async def _call_remote(self, payload: Dict[str, Any]) -> str:
        if not self._client:
            raise RuntimeError("LLM client æœªé…ç½®ï¼Œæ— æ³•è°ƒç”¨è¿œç¨‹æŽ¥å£")
        prompt = self._build_prompt(payload)
        def _sync_call() -> str:
            stream = self._client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å½©å°è¶ï¼Œä½ ä¼šæ ¹æ®æä¾›çš„åŠ³åŠ¨è¡¨çŽ°ä¿¡æ¯ï¼Œä¸ºå­¦ç”ŸæŽ¨è1-3ä¸ªæœªæ¥å¯ä»¥å‘å±•çš„èŒä¸šã€‚ç”¨ä¸­æ–‡å›žç­”ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                stream=True,
            )
            chunks: list[str] = []
            for chunk in stream:
                if not chunk.choices:
                    continue
                delta = getattr(chunk.choices[0], "delta", None)
                content = getattr(delta, "content", None) if delta else None
                if content:
                    chunks.append(content)
            return "".join(chunks)

        return await asyncio.to_thread(_sync_call)

    def _parse_careers(self, raw_response: str) -> list[str]:
        try:
            data = json.loads(raw_response)
            if isinstance(data, dict) and isinstance(data.get("careers"), list):
                return [
                    str(item).strip()
                    for item in data["careers"]
                    if str(item).strip()
                ][:3]
            if isinstance(data, list):
                return [str(item).strip() for item in data if str(item).strip()][:3]
        except json.JSONDecodeError:
            pass
        tokens = [token.strip() for token in raw_response.replace("\n", "ï¼Œ").split("ï¼Œ")]
        return [token for token in tokens if token][:3]

    def _build_output_message(
        self,
        payload: Dict[str, Any],
        raw_response: str,
    ) -> tuple[str, list[str]]:
        categories = payload.get("selected_categories") or []
        category_text = "ã€".join(categories) if categories else "å¤šç§åŠ³åŠ¨å®žè·µ"
        careers = self._parse_careers(raw_response)
        if not careers:
            careers = ["åŠ³åŠ¨æ•™è‚²æŽ¨å¹¿è€…"]
        career_text = "ã€".join(careers)
        message = (
            "ðŸ˜Šäº²çˆ±çš„è¶å®ï¼š\n"
            "      åœ¨å®¶é‡Œä½ èƒ½ä¸»åŠ¨åˆ†æ‹…å®¶åŠ¡åŠ³åŠ¨ï¼Œåœ¨å­¦æ ¡è®¤çœŸå®Œæˆç­çº§åŠ³åŠ¨ã€æ ¡å›­åŠ³åŠ¨ï¼Œè¿˜ç§¯æžå‚åŠ ç¤¾ä¼šå®žè·µðŸ˜²ðŸ‘ï¼ŒåŸ¹å…»äº†åšæ¯…æ‹…è´£ã€å‹¤åŠ³è¯šå®žã€åˆä½œæ™ºæ…§çš„ç¾Žå¥½å“æ ¼ðŸ¤©ï¼›"
            f"ä½ ç‰¹åˆ«æ“…é•¿{category_text}ï¼Œå¸Œæœ›ä½ èƒ½ç»§ç»­å‘æŒ¥è¿™ä¸€ä¼˜åŠ¿ï¼Œæœªæ¥ä¹Ÿè®¸èƒ½å¤Ÿæˆä¸ºä¸€åä¼˜ç§€çš„{career_text}å“¦ðŸ¥³ï¼"
        )
        return message, careers

    def _build_prompt(self, payload: Dict[str, Any]) -> str:
        context = {
            "selected_categories": payload.get("selected_categories", []),
            "selected_traits": payload.get("selected_traits", []),
            "composite_scores": payload.get("composite_scores", {}),
            "parent_note": payload.get("parent_note", ""),
            "teacher_review_text": payload.get("teacher_review_text", ""),
            "grade_band": payload.get("grade_band"),
        }
        instruction = (
            "ä½ ä¼šæ ¹æ®æä¾›çš„åŠ³åŠ¨è¡¨çŽ°ä¿¡æ¯ï¼Œä¸ºå­¦ç”ŸæŽ¨è1-3ä¸ªæœªæ¥å¯ä»¥å‘å±•çš„èŒä¸šã€‚\n"
            "è¯·ç»¼åˆè€ƒè™‘å­¦ç”Ÿæ“…é•¿çš„åŠ³åŠ¨ç±»åˆ«ã€å“æ ¼æå‡ã€ç»¼åˆå“è´¨å¾—åˆ†ã€å®¶é•¿å¯„è¯­å’Œæ•™å¸ˆè¯„ä»·ï¼Œè¾“å‡ºæœ€å¥‘åˆçš„å…·ä½“èŒä¸šã€‚\n"
            "è¾“å‡ºå¿…é¡»æ˜¯ JSON å¯¹è±¡ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š{\"careers\": [\"èŒä¸š1\", \"èŒä¸š2\"]}ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"
        )
        return instruction + "\nã€å‚è€ƒä¿¡æ¯ã€‘\n" + json.dumps(context, ensure_ascii=False, indent=2)


def build_llm_payload(
    survey: SurveyResponse,
    parent_note: ParentNote | None,
    teacher_review: TeacherReview,
    composite: Optional[CompositeResponse],
) -> Dict[str, Any]:
    rng = random.Random(str(survey.student_id))
    category_scores, category_traits = _compute_category_statistics(survey)
    selected_categories = _select_top_labels(category_scores, 3, rng)

    trait_counter: Counter[str] = Counter()
    for category in selected_categories:
        trait_counter.update(category_traits.get(category, []))

    selected_traits = _select_top_labels(
        {name: float(count) for name, count in trait_counter.items()},
        3,
        rng,
    )

    composite_summary = _extract_composite_summary(composite)

    return {
        "selected_categories": selected_categories,
        "selected_traits": selected_traits,
        "composite_scores": composite_summary,
        "parent_note": parent_note.content if parent_note else "",
        "teacher_review_text": teacher_review.rendered_text,
        "grade_band": survey.grade_band.value if survey.grade_band else None,
    }
